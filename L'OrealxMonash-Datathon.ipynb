{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8f23ca7-a6d6-4d76-b1cd-8837fb5d1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3838f61-0e7d-42e4-87a0-f792b1eb21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment5 = pd.read_csv(\"comments5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f9d4d5-ecf5-41d3-944d-9515bf5150ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comments 5\n",
      "              kind  commentId  channelId  videoId  authorId  \\\n",
      "0  youtube#comment     600702      21224    91712    463359   \n",
      "1  youtube#comment     549057      50201    53793   1125630   \n",
      "2  youtube#comment     804966      29145    61224   3309637   \n",
      "3  youtube#comment    1302885      13098    30730   1408547   \n",
      "4  youtube#comment    2744696      48794    31684    777869   \n",
      "\n",
      "                                        textOriginal  parentCommentId  \\\n",
      "0                                            So true              NaN   \n",
      "1                                                ü§Øüò≤üò≥              NaN   \n",
      "2                                               Link              NaN   \n",
      "3  Half of those skincare came from different cul...              NaN   \n",
      "4                         She‚Äôs the twin of Timothee              NaN   \n",
      "\n",
      "   likeCount                publishedAt                  updatedAt  \n",
      "0          0  2024-04-22 15:14:26+00:00  2024-04-22 15:14:26+00:00  \n",
      "1          0  2025-01-08 15:33:21+00:00  2025-01-08 15:33:21+00:00  \n",
      "2          0  2024-08-29 14:43:58+00:00  2024-08-29 14:43:58+00:00  \n",
      "3          2  2025-07-03 12:02:23+00:00  2025-07-03 12:02:23+00:00  \n",
      "4          0  2024-06-05 11:34:49+00:00  2024-06-05 11:34:49+00:00  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComments 5\")\n",
    "print(comment5.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4b13a2-5ff0-4464-91b0-332213396b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMENT 5\n",
      "\n",
      "Missing values per column:\n",
      "kind                    0\n",
      "commentId               0\n",
      "channelId               0\n",
      "videoId                 0\n",
      "authorId                0\n",
      "textOriginal           39\n",
      "parentCommentId    645633\n",
      "likeCount               0\n",
      "publishedAt             0\n",
      "updatedAt               0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows:\n",
      "0\n",
      "\n",
      "Shape before dropping duplicates:\n",
      "(725015, 10)\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(725015, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"COMMENT 5\")\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(comment5.isnull().sum())\n",
    "\n",
    "print(\"\\nNumber of duplicate rows:\")\n",
    "print(comment5.duplicated().sum())\n",
    "\n",
    "print(\"\\nShape before dropping duplicates:\")\n",
    "print(comment5.shape)\n",
    "\n",
    "comment5.drop_duplicates(inplace=True)\n",
    "print(\"\\nDataFrame shape after dropping duplicates:\")\n",
    "print(comment5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed963f1b-1362-4668-be09-4f641e5f84f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                kind  videoId                publishedAt  channelId  \\\n",
      "0      youtube#video    85806  2024-01-15 00:59:29+00:00      33807   \n",
      "1      youtube#video    30556  2023-10-27 19:32:16+00:00      46650   \n",
      "2      youtube#video    51771  2024-09-28 01:23:22+00:00      14346   \n",
      "3      youtube#video    45298  2023-07-13 15:19:28+00:00      50139   \n",
      "4      youtube#video    43611  2023-04-29 18:47:37+00:00       8143   \n",
      "...              ...      ...                        ...        ...   \n",
      "92754  youtube#video    26001  2023-12-28 21:04:42+00:00      35305   \n",
      "92755  youtube#video    34584  2021-04-15 12:08:32+00:00       6127   \n",
      "92756  youtube#video    21075  2023-04-27 04:07:06+00:00       7271   \n",
      "92757  youtube#video    44523  2025-04-27 11:16:59+00:00      42969   \n",
      "92758  youtube#video    46938  2024-12-02 05:04:56+00:00      14677   \n",
      "\n",
      "                                                   title  \\\n",
      "0      Unlocking the Benefits of Face Masks for Skin ...   \n",
      "1      Get ready for the Magicüíöüíúü§çüíù‚ú® #hydration #glowi...   \n",
      "2      #trending #makeup #beautymakeup #yslbeauty #lu...   \n",
      "3                                  #shortvedio #balayage   \n",
      "4      Full Face of Merit Beauty ü§é featuring new Flus...   \n",
      "...                                                  ...   \n",
      "92754                New Year Styling! | #Beachwaver Co.   \n",
      "92755                 DIY glow serum / in urdu and hindi   \n",
      "92756  How Women at 50 Stay Young‚ùì#wrinkles #senescen...   \n",
      "92757       makeup try #face primer#concealer#faondation   \n",
      "92758  #amazing #concealer #hack #shortvideo #youtube...   \n",
      "\n",
      "                                             description  \\\n",
      "0                                                    NaN   \n",
      "1                                                    NaN   \n",
      "2                                                    NaN   \n",
      "3                                                    NaN   \n",
      "4                                                    NaN   \n",
      "...                                                  ...   \n",
      "92754  Connect with us and keep up with our brand! Pl...   \n",
      "92755     #shortvideo#\\n#youtubeshortvideo#\\n#glowserum#   \n",
      "92756                                           @Jeffree   \n",
      "92757                                                NaN   \n",
      "92758                                                NaN   \n",
      "\n",
      "                                                    tags defaultLanguage  \\\n",
      "0                                                    NaN           en-US   \n",
      "1                                                    NaN             NaN   \n",
      "2                                                    NaN             NaN   \n",
      "3                                                    NaN             NaN   \n",
      "4                                                    NaN             NaN   \n",
      "...                                                  ...             ...   \n",
      "92754  ['Beachwaver', 'DreamBigMakeWaves', 'Hair Care...             NaN   \n",
      "92755                                                NaN             NaN   \n",
      "92756                                                NaN             NaN   \n",
      "92757                                                NaN           en-IN   \n",
      "92758                                                NaN             NaN   \n",
      "\n",
      "      defaultAudioLanguage contentDuration  viewCount  likeCount  \\\n",
      "0                    en-US            PT9S       72.0        0.0   \n",
      "1                      NaN           PT45S      257.0        7.0   \n",
      "2                    en-US           PT19S      164.0        4.0   \n",
      "3                      NaN           PT14S     1207.0       20.0   \n",
      "4                       en           PT56S     8647.0      268.0   \n",
      "...                    ...             ...        ...        ...   \n",
      "92754                   en           PT30S     1485.0       29.0   \n",
      "92755                  NaN           PT31S       24.0        4.0   \n",
      "92756                  NaN           PT12S     1422.0       10.0   \n",
      "92757                   hi           PT22S       75.0        1.0   \n",
      "92758                   hi           PT13S      584.0       28.0   \n",
      "\n",
      "       favouriteCount  commentCount  \\\n",
      "0                 0.0           0.0   \n",
      "1                 0.0           0.0   \n",
      "2                 0.0           2.0   \n",
      "3                 0.0           0.0   \n",
      "4                 0.0           7.0   \n",
      "...               ...           ...   \n",
      "92754             0.0           0.0   \n",
      "92755             0.0           0.0   \n",
      "92756             0.0           3.0   \n",
      "92757             0.0           0.0   \n",
      "92758             0.0           0.0   \n",
      "\n",
      "                                         topicCategories  \n",
      "0      ['https://en.wikipedia.org/wiki/Health', 'http...  \n",
      "1      ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
      "2      ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
      "3      ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
      "4      ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
      "...                                                  ...  \n",
      "92754  ['https://en.wikipedia.org/wiki/Fashion', 'htt...  \n",
      "92755  ['https://en.wikipedia.org/wiki/Hobby', 'https...  \n",
      "92756  ['https://en.wikipedia.org/wiki/Health', 'http...  \n",
      "92757  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
      "92758  ['https://en.wikipedia.org/wiki/Lifestyle_(soc...  \n",
      "\n",
      "[92759 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "videos = pd.read_csv(\"videos.csv\")\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf088d3-511b-4f12-a48f-0da95f2f22e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "kind                        0\n",
      "videoId                     0\n",
      "publishedAt                 0\n",
      "channelId                   0\n",
      "title                       0\n",
      "description             57522\n",
      "tags                    71868\n",
      "defaultLanguage         76974\n",
      "defaultAudioLanguage    62803\n",
      "contentDuration          1267\n",
      "viewCount                1269\n",
      "likeCount                6129\n",
      "favouriteCount           1267\n",
      "commentCount             2465\n",
      "topicCategories          1531\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicate rows:\n",
      "0\n",
      "\n",
      "Shape before dropping duplicates:\n",
      "(92759, 15)\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(92759, 15)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(videos.isnull().sum())\n",
    "\n",
    "print(\"\\nNumber of duplicate rows:\")\n",
    "print(videos.duplicated().sum())\n",
    "\n",
    "print(\"\\nShape before dropping duplicates:\")\n",
    "print(videos.shape)\n",
    "\n",
    "videos.drop_duplicates(inplace=True)\n",
    "print(\"\\nDataFrame shape after dropping duplicates:\")\n",
    "print(videos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84fc9e83-18fe-4366-a6e4-b3fa4bde24e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        textOriginal  \\\n",
      "0                                            So true   \n",
      "1                                                ü§Øüò≤üò≥   \n",
      "2                                               Link   \n",
      "3  Half of those skincare came from different cul...   \n",
      "4                         She‚Äôs the twin of Timothee   \n",
      "\n",
      "                                          clean_text  likeCount  \\\n",
      "0                                            so true          0   \n",
      "1                                                ü§Øüò≤üò≥          0   \n",
      "2                                               link          0   \n",
      "3  half of those skincare came from different cul...          2   \n",
      "4                         she‚Äôs the twin of timothee          0   \n",
      "\n",
      "   likeCount_norm               publishedAt  published_year  published_month  \n",
      "0        0.000000 2024-04-22 15:14:26+00:00            2024                4  \n",
      "1        0.000000 2025-01-08 15:33:21+00:00            2025                1  \n",
      "2        0.000000 2024-08-29 14:43:58+00:00            2024                8  \n",
      "3        1.098612 2025-07-03 12:02:23+00:00            2025                7  \n",
      "4        0.000000 2024-06-05 11:34:49+00:00            2024                6  \n",
      "‚úÖ Preprocessing complete. Cleaned dataset saved as comments5_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "# === Load dataset ===\n",
    "file_path = \"comments5.csv\"   # change path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# === Make a copy ===\n",
    "df_clean = df.copy()\n",
    "\n",
    "# 1. Drop redundant column\n",
    "if \"kind\" in df_clean.columns:\n",
    "    df_clean = df_clean.drop(columns=['kind'])\n",
    "\n",
    "# 2. Handle missing values (remove rows with missing comments)\n",
    "df_clean = df_clean.dropna(subset=['textOriginal']).reset_index(drop=True)\n",
    "\n",
    "# 3. Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # remove URLs\n",
    "    text = re.sub(r'<.*?>', '', text)  # remove HTML tags\n",
    "    text = re.sub(r'[0-9]+', '', text)  # remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning\n",
    "df_clean['clean_text'] = df_clean['textOriginal'].apply(clean_text)\n",
    "\n",
    "# 4. Convert datetime columns\n",
    "df_clean['publishedAt'] = pd.to_datetime(df_clean['publishedAt'], errors='coerce')\n",
    "df_clean['updatedAt'] = pd.to_datetime(df_clean['updatedAt'], errors='coerce')\n",
    "\n",
    "# 5. Extract useful time features\n",
    "df_clean['published_year'] = df_clean['publishedAt'].dt.year\n",
    "df_clean['published_month'] = df_clean['publishedAt'].dt.month\n",
    "df_clean['published_day'] = df_clean['publishedAt'].dt.day\n",
    "df_clean['published_hour'] = df_clean['publishedAt'].dt.hour\n",
    "\n",
    "# 6. Handle parentCommentId (fill NaN with 0)\n",
    "df_clean['parentCommentId'] = df_clean['parentCommentId'].fillna(0).astype(int)\n",
    "\n",
    "# 7. Normalize likeCount (log transform to reduce skew)\n",
    "df_clean['likeCount_norm'] = np.log1p(df_clean['likeCount'])\n",
    "\n",
    "# === Preview the cleaned dataset ===\n",
    "print(df_clean[['textOriginal', 'clean_text', 'likeCount', \n",
    "                'likeCount_norm', 'publishedAt', \n",
    "                'published_year', 'published_month']].head())\n",
    "\n",
    "# === Save cleaned dataset ===\n",
    "df_clean.to_csv(\"comments5_cleaned.csv\", index=False)\n",
    "print(\"‚úÖ Preprocessing complete. Cleaned dataset saved as comments5_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab24ddc7-d182-490e-86aa-adefd46f5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Unlocking the Benefits of Face Masks for Skin ...   \n",
      "1  Get ready for the Magicüíöüíúü§çüíù‚ú® #hydration #glowi...   \n",
      "2  #trending #makeup #beautymakeup #yslbeauty #lu...   \n",
      "3                              #shortvedio #balayage   \n",
      "4  Full Face of Merit Beauty ü§é featuring new Flus...   \n",
      "\n",
      "                                         clean_title  viewCount  \\\n",
      "0  unlocking the benefits of face masks for skin ...       72.0   \n",
      "1  get ready for the magicüíöüíúü§çüíù‚ú® hydration glowing...      257.0   \n",
      "2  trending makeup beautymakeup yslbeauty luxury ...      164.0   \n",
      "3                                shortvedio balayage     1207.0   \n",
      "4  full face of merit beauty ü§é featuring new flus...     8647.0   \n",
      "\n",
      "   viewCount_norm clean_tags                                   clean_topics  \n",
      "0        4.290459                              health lifestyle (sociology)  \n",
      "1        5.552960             lifestyle (sociology) physical attractiveness  \n",
      "2        5.105945             lifestyle (sociology) physical attractiveness  \n",
      "3        7.096721             lifestyle (sociology) physical attractiveness  \n",
      "4        9.065083             lifestyle (sociology) physical attractiveness  \n",
      "‚úÖ Preprocessing complete. Cleaned dataset saved as videos_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import ast\n",
    "\n",
    "# === Load dataset ===\n",
    "videos = pd.read_csv(\"videos.csv\")\n",
    "\n",
    "# === Make a copy ===\n",
    "videos_clean = videos.copy()\n",
    "\n",
    "# 1. Drop redundant column\n",
    "if \"kind\" in videos_clean.columns:\n",
    "    videos_clean = videos_clean.drop(columns=[\"kind\"])\n",
    "\n",
    "# 2. Handle missing values\n",
    "# Fill text NaNs with empty string\n",
    "for col in [\"title\", \"description\", \"tags\"]:\n",
    "    videos_clean[col] = videos_clean[col].fillna(\"\")\n",
    "\n",
    "# 3. Text cleaning function\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)  # remove HTML tags\n",
    "    text = re.sub(r\"[0-9]+\", \"\", text)  # remove numbers\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to textual fields\n",
    "videos_clean[\"clean_title\"] = videos_clean[\"title\"].apply(clean_text)\n",
    "videos_clean[\"clean_description\"] = videos_clean[\"description\"].apply(clean_text)\n",
    "\n",
    "# Tags are stored as string representations of lists ‚Üí parse them\n",
    "def clean_tags(tags):\n",
    "    try:\n",
    "        if isinstance(tags, str) and tags.startswith(\"[\"):\n",
    "            tags_list = ast.literal_eval(tags)\n",
    "            tags_list = [clean_text(t) for t in tags_list]\n",
    "            return \" \".join(tags_list)\n",
    "        else:\n",
    "            return clean_text(tags)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "videos_clean[\"clean_tags\"] = videos_clean[\"tags\"].apply(clean_tags)\n",
    "\n",
    "# 4. Convert datetime\n",
    "videos_clean[\"publishedAt\"] = pd.to_datetime(videos_clean[\"publishedAt\"], errors=\"coerce\")\n",
    "\n",
    "# Extract datetime features\n",
    "videos_clean[\"published_year\"] = videos_clean[\"publishedAt\"].dt.year\n",
    "videos_clean[\"published_month\"] = videos_clean[\"publishedAt\"].dt.month\n",
    "videos_clean[\"published_day\"] = videos_clean[\"publishedAt\"].dt.day\n",
    "videos_clean[\"published_hour\"] = videos_clean[\"publishedAt\"].dt.hour\n",
    "\n",
    "# 5. Handle numeric columns (fill NaNs with 0)\n",
    "for col in [\"viewCount\", \"likeCount\", \"favouriteCount\", \"commentCount\"]:\n",
    "    videos_clean[col] = videos_clean[col].fillna(0)\n",
    "\n",
    "# Normalize (log transform)\n",
    "videos_clean[\"viewCount_norm\"] = np.log1p(videos_clean[\"viewCount\"])\n",
    "videos_clean[\"likeCount_norm\"] = np.log1p(videos_clean[\"likeCount\"])\n",
    "videos_clean[\"commentCount_norm\"] = np.log1p(videos_clean[\"commentCount\"])\n",
    "\n",
    "# 6. Clean topicCategories (list of URLs)\n",
    "def clean_topics(topic_str):\n",
    "    try:\n",
    "        if isinstance(topic_str, str) and topic_str.startswith(\"[\"):\n",
    "            topics = ast.literal_eval(topic_str)\n",
    "            topics = [t.split(\"/\")[-1].replace(\"_\", \" \").lower() for t in topics]\n",
    "            return \" \".join(topics)\n",
    "        else:\n",
    "            return \"\"\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "videos_clean[\"clean_topics\"] = videos_clean[\"topicCategories\"].apply(clean_topics)\n",
    "\n",
    "# === Preview cleaned data ===\n",
    "print(videos_clean[[\"title\", \"clean_title\", \"viewCount\", \"viewCount_norm\", \"clean_tags\", \"clean_topics\"]].head())\n",
    "\n",
    "# === Save cleaned dataset ===\n",
    "videos_clean.to_csv(\"videos_cleaned.csv\", index=False)\n",
    "print(\"‚úÖ Preprocessing complete. Cleaned dataset saved as videos_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d31e1-b9be-42bc-bc93-d03370143918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a9fcf-1395-450d-bb10-1884cc585454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
